{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto relode\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ctrl model dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "\n",
    "class CtrlModelDataset:\n",
    "    def __init__(self, path_to_pickle_files, num_past_time_steps, num_future_time_steps):\n",
    "        self.path_to_pickle_files = path_to_pickle_files\n",
    "        self.num_past_time_steps = num_past_time_steps\n",
    "        self.num_future_time_steps = num_future_time_steps\n",
    "\n",
    "        pickl_files = glob.glob(self.path_to_pickle_files + '/*')\n",
    "        \n",
    "        # read all pickle files\n",
    "        self.data = []\n",
    "        for pickle_file in pickl_files:\n",
    "            with open(pickle_file, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                self.data.extend(data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        past_inputs = self.data[idx]['past_inputs'][0, :, :]\n",
    "        past_outputs = self.data[idx]['past_outputs'][0, :, :]\n",
    "        past_interals = self.data[idx]['past_interals'][0, :, :]\n",
    "        future_outputs = self.data[idx]['future_infered_outputs'][0, :, :self.num_future_time_steps]\n",
    "        next_input = self.data[idx]['future_optimized_inputs'][0, :, 0]\n",
    "    \n",
    "        return past_inputs, past_outputs, past_interals, future_outputs, next_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_model_dataset = CtrlModelDataset('./ctrl_datasets', 30, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ctrl_model_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ctrl_model_dataloader = DataLoader(ctrl_model_dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ctrl model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctrl_model import CtrlModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_model = CtrlModel(\n",
    "    num_past_time_steps=30,\n",
    "    num_future_time_steps=30,\n",
    "    num_input_vars=2,\n",
    "    num_output_vars=1,\n",
    "    num_internal_vars=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sample from the dataset\n",
    "past_inputs, past_outputs, past_interals, future_outputs, next_input = ctrl_model_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0720],\n",
       "         [ 0.2677]]], grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctrl_model(\n",
    "    past_inputs=past_inputs.unsqueeze(0),\n",
    "    past_outputs=past_outputs.unsqueeze(0),\n",
    "    past_interals=past_interals.unsqueeze(0),\n",
    "    future_outputs=future_outputs.unsqueeze(0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nils/miniconda3/envs/i2dl/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:446: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type   | Params\n",
      "-----------------------------------\n",
      "0 | conv1   | Conv1d | 100   \n",
      "1 | conv2   | Conv1d | 620   \n",
      "2 | conv3   | Conv1d | 5.3 K \n",
      "3 | fc1     | Linear | 9.2 K \n",
      "4 | conv_f1 | Conv1d | 12    \n",
      "5 | conv_f2 | Conv1d | 30    \n",
      "6 | fc_new2 | Linear | 9.1 K \n",
      "7 | fc_new3 | Linear | 620   \n",
      "8 | fc_new4 | Linear | 42    \n",
      "-----------------------------------\n",
      "25.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "25.0 K    Total params\n",
      "0.100     Total estimated model params size (MB)\n",
      "/home/nils/miniconda3/envs/i2dl/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea9e88e5a3e443278b2a0da3f3336152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nils/repos/w22-test-bench/controllers/nn_1/dev/ctrl_model/ctrl_model.py:198: UserWarning: Using a target size (torch.Size([2, 2])) that is different to the input size (torch.Size([2, 2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = torch.nn.functional.mse_loss(next_predicted_input, next_input)\n",
      "/home/nils/repos/w22-test-bench/controllers/nn_1/dev/ctrl_model/ctrl_model.py:198: UserWarning: Using a target size (torch.Size([1, 2])) that is different to the input size (torch.Size([1, 2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = torch.nn.functional.mse_loss(next_predicted_input, next_input)\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "# train using pytorch lightning\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=10\n",
    ")\n",
    "\n",
    "trainer.fit(ctrl_model, ctrl_model_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2473d8b9e246462e8f41a55546d99c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            4.981675148010254\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 4.981675148010254}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the average loss\n",
    "trainer.test(ctrl_model, ctrl_model_dataloader)\n",
    "# [{'test_loss': 5.459200859069824}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "i2dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b172aa64e99151ae5a8f8d9245b3245f8b4db3f2ddd051e6d003cb9af5f4340"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
