{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["I-ffRZ0UW1eE","RKMt1nBByjv7","z3CY20seFUFT"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# **G2P Algorithm for Roboy NTC**\n","Please check https://miro.com/app/board/uXjVP2DvcmU=/ to get an overview\n","\n","---\n","\n"],"metadata":{"id":"9UbrvXwr-ZVC"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cjwjxX1Ban3x","executionInfo":{"status":"ok","timestamp":1679345661649,"user_tz":-60,"elapsed":31090,"user":{"displayName":"Marcel Kück","userId":"09092862230391330585"}},"outputId":"d500820c-73c1-4c1c-e431-330937eaf7ee"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"XfOFbWpn4jT1","executionInfo":{"status":"ok","timestamp":1679345831092,"user_tz":-60,"elapsed":3968,"user":{"displayName":"Marcel Kück","userId":"09092862230391330585"}}},"outputs":[],"source":["#Imports\n","import tensorflow as tf\n","from tensorflow.keras import regularizers\n","import numpy as np\n","import pandas as pd\n","import sklearn\n","from scipy import signal\n","from matplotlib import pyplot as plt\n","from sklearn.neural_network import MLPRegressor\n","from sklearn.preprocessing import MinMaxScaler"]},{"cell_type":"code","source":["#prepare data for training\n","df = pd.read_csv('/content/drive/MyDrive/Roboy/bench_data_2.csv')\n","\n","#simple dataset: similar to Ali's approach\n","kinematics = df[['angle', 'angular_vel', 'angular_acc']].values\n","\n","#extended dataset with more features for kinematics data #TODO: Eliminate unessesary features \n","kinematics_extended = df[[\n","    'timestamp',\n","    'angle',\n","    'kill_switch_pressed',\n","    'flex_pv_pos_encoder',\n","    'flex_pv_torque_encoder',\n","    'flex_pv_current',\n","    'flex_sp_pwm',\n","    'flex_active',\n","    'extend_pv_pos_encoder',\n","    'extend_pv_torque_encoder',\n","    'extend_pv_current',\n","    'extend_sp_pwm',\n","    'extend_active',\n","    'angular_acc',\n","    'angular_vel'\n","]].values\n","\n","activations = df[['flex_sp_pwm','extend_sp_pwm']].values"],"metadata":{"id":"49aOVmmGb9We","executionInfo":{"status":"ok","timestamp":1679346456808,"user_tz":-60,"elapsed":408,"user":{"displayName":"Marcel Kück","userId":"09092862230391330585"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# **Inverse Kinematics (Solving for non-linear regression problem)**"],"metadata":{"id":"tvBusvHryU8i"}},{"cell_type":"code","source":["#Training Data\n","x = kinematics\n","y = activations\n","\n","#Scale Data for training\n","scalerIn = MinMaxScaler()\n","scalerOut = MinMaxScaler()\n","x_scaled = scalerIn.fit_transform(x)\n","y_scaled = scalerOut.fit_transform(y)\n","\n","#Split unscaled data \n","x_train, x_valid, y_train, y_valid = sklearn.model_selection.train_test_split(x, y, test_size=0.2)\n","\n","#Split scaled data\n","x_train_scaled, x_valid_scaled, y_train_scaled, y_valid_scaled = sklearn.model_selection.train_test_split(x_scaled, y_scaled, test_size=0.2)"],"metadata":{"id":"hqs1_ZZIfJQk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Approach 0: MLP to solve regression problem (Ali's implementation without significant changes)\n","def inverse_mapping_fcn0():\n","\n","  model = tf.keras.Sequential()\n","  # Adds a densely-connected layer with 15 units to the model:\n","  model.add(tf.keras.layers.Dense(15, activation='relu'))\n","  # Add a softmax layer with 3 output units:\n","  model.add(tf.keras.layers.Dense(2, activation='sigmoid'))\n","  model.compile(optimizer=tf.keras.optimizers.SGD(),\n","              loss='mse',       # mean squared error\n","              metrics=['mse'])  # mean squared error\n","  #training the model\n","  history = \\\n","  model.fit(\n","  x_train_scaled,\n","  y_train_scaled,\n","  epochs=20,\n","  validation_data=(x_valid_scaled, y_valid_scaled))\n","\n","  return (model, history)\n","  \n","\n","def inverse_mapping_fcn0_1():\n","  model = MLPRegressor(\n","      hidden_layer_sizes=15,\n","      activation=\"logistic\",\n","      verbose=True,\n","      warm_start=True,\n","      early_stopping=True)\n","\n","  history = model.fit(x_train_scaled, y_train_scaled)\n"," \n","  return (model, history)"],"metadata":{"id":"8UgbFiNTFQM_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"################################## Model 0 (Ali's Model) ##################################\")\n","\n","[model0, history0] = inverse_mapping_fcn0()\n","\n","# Get the validation loss from the model's history\n","val_loss = history0.history['val_loss']\n","\n","# Create a figure and axes\n","fig, ax = plt.subplots()\n","\n","# Plot the validation loss\n","ax.plot(val_loss, label='Validation Loss')\n","\n","# Set the x-axis label\n","ax.set_xlabel('Epoch')\n","\n","# Set the y-axis label\n","ax.set_ylabel('Loss')\n","\n","# Add a title\n","ax.set_title('Loss Model 0')\n","\n","# Add a legend\n","ax.legend()\n","\n","# Show the plot\n","plt.show()"],"metadata":{"id":"X1qwzIp4HpfI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Approach 1: DNN to solve regression problem\n","def inverse_mapping_fcn1():\n","\n","  #Define Model and apply dropout and L2 regularisation to prevent overfitting\n","  #Use non linear activation (tanh) for non linear regression\n","  model = tf.keras.Sequential()\n","\n","  model.add(tf.keras.layers.Dense(32, input_shape=(3,), activation='relu', kernel_regularizer = regularizers.l2(0.01)))\n","  model.add(tf.keras.layers.Dropout(0.2))\n","  model.add(tf.keras.layers.Dense(64, activation='relu', kernel_regularizer = regularizers.l2(0.01)))\n","  model.add(tf.keras.layers.Dropout(0.2))\n","  model.add(tf.keras.layers.Dense(4, activation='relu', kernel_regularizer = regularizers.l2(0.01)))\n","  model.add(tf.keras.layers.Dense(units=2, activation='tanh'))\n","\n","  #Compile the model\n","  model.compile(loss='mean_squared_error', optimizer= tf.optimizers.Adam(0.001), metrics=['mse'])\n","\n","  # Define the early stopping callback\n","  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='mse', patience=10)\n","\n","  #Train the model for 100 epochs and allow early stopping\n","  history = model.fit(x_train_scaled, y_train_scaled, epochs=100, validation_data=(x_valid_scaled, y_valid_scaled), callbacks=[early_stopping], batch_size=256)\n","\t\n","  return (model, history)"],"metadata":{"id":"giDc1DiE55yK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#call function\n","print(\"################################## Model 1 ##################################\")\n","[model1, history1] = inverse_mapping_fcn1()\n","\n","# Get the training and validation loss from the model's history\n","val_loss = history1.history['val_loss']\n","\n","# Create a figure and axes\n","fig, ax1 = plt.subplots()\n","\n","# Plot the training and validation loss\n","ax1.plot(val_loss, label='Validation Loss')\n","\n","# Set the x-axis label\n","ax1.set_xlabel('Epoch')\n","\n","# Set the y-axis label\n","ax1.set_ylabel('Loss')\n","\n","# Add a title\n","ax1.set_title('Loss Model 1')\n","\n","# Add a legend\n","ax1.legend()\n","\n","# Show the plot\n","plt.show()"],"metadata":{"id":"rmnH26UTH97m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Approach 2: Simple MLP to solve regression problem\n","def inverse_mapping_fcn2():\n","\n","  model = MLPRegressor(\n","\t\t\thidden_layer_sizes = (50,2),\n","      max_iter = 300,\n","      solver = \"adam\",\n","\t\t\tactivation = \"logistic\",\n","\t\t\tverbose = True,\n","\t\t\twarm_start = True,\n","\t\t\tearly_stopping = True)\n","  \n","  history = model.fit(x_train_scaled,y_train_scaled) #splits data internally\n","\n","  return (model, history)"],"metadata":{"id":"q6ggnYiGe0zt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#call function\n","print(\"################################## Model 2 ##################################\")\n","[model2, history2] = inverse_mapping_fcn2()\n","\n","# Create figure and subplots\n","fig, ax2 = plt.subplots()\n","\n","# Plot loss\n","ax2.plot(history2.loss_curve_, label='Validation Loss')\n","ax2.set_title('Loss Model 2')\n","ax2.set_xlabel('Epoch')\n","ax2.set_ylabel('Loss')\n","ax2.legend()\n","\n","# Show the plot\n","plt.show()"],"metadata":{"id":"L0OYJiQ0ILo8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Approach 3: Deep MLP to solve regression problem\n","def inverse_mapping_fcn3():\n","\n","  model = MLPRegressor(\n","\t\t\thidden_layer_sizes = (60,3),\n","      max_iter = 300,\n","      solver = \"adam\",\n","\t\t\tactivation = \"logistic\",\n","\t\t\tverbose = True,\n","\t\t\twarm_start = True,\n","\t\t\tearly_stopping = True)\n","  \n","  history = model.fit(x_train_scaled, y_train_scaled)\n","\n","  return (model, history)"],"metadata":{"id":"bb3nEjXoZygA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#call function\n","print(\"################################## Model 3 ##################################\")\n","[model3, history3] = inverse_mapping_fcn3()\n","\n","# Create figure and subplots\n","fig, ax3 = plt.subplots()\n","\n","# Plot loss\n","ax3.plot(history3.loss_curve_, label='Validation Loss')\n","ax3.set_title('Loss Model 3')\n","ax3.set_xlabel('Epoch')\n","ax3.set_ylabel('Loss')\n","ax3.legend()\n","\n","# Show the plot\n","plt.show()"],"metadata":{"id":"j2Efo3hXIQPO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Approach 4: RNN (LSTM) to solve regression problem\n","\n","def inverse_mapping_fcn4():\n","\n","  x_train_lstm = x_train_scaled.reshape(x_train_scaled.shape[0], 1, x_train_scaled.shape[1])\n","  x_valid_lstm = x_valid_scaled.reshape(x_valid_scaled.shape[0], 1, x_valid_scaled.shape[1])\n","\n","  # Define the model architecture\n","  model = tf.keras.Sequential()\n","  model.add(tf.keras.layers.LSTM(32, input_shape=(1,3), return_sequences=True))\n","  model.add(tf.keras.layers.LSTM(4, return_sequences=False))\n","  model.add(tf.keras.layers.Dense(2, activation='tanh'))\n","\n","  # Define the early stopping callback\n","  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='mse', patience=10)\n","\n","  #compile model\n","  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mse'])\n","\n","  #Train the model for 100 epochs and allow early stopping\n","  history = model.fit(x_train_lstm, y_train_scaled, epochs=100, validation_data=(x_valid_lstm, y_valid_scaled), callbacks=[early_stopping], batch_size=256)\n","\t\n","  return (model, history)"],"metadata":{"id":"9nBWjy848pmi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#call function\n","print(\"################################## Model 4 ##################################\")\n","[model4, history4] = inverse_mapping_fcn4()\n","\n","# Create figure and subplots\n","fig, ax4 = plt.subplots()\n","\n","# Plot loss\n","ax4.plot(history4.history['val_loss'], label='Validation Loss')\n","ax4.set_title('Loss')\n","ax4.set_title('Loss Model 4')\n","ax4.set_xlabel('Epoch')\n","ax4.set_ylabel('Loss')\n","ax4.legend()\n","\n","# Show the plot\n","plt.show()"],"metadata":{"id":"fbHuS1tG-Gri"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Approach 5: RNN to learn correlation between samples. This completly new approach is supposed to learn how to connect multiple samples simultaniously.\n","\n","def inverse_mapping_fcn5(seq_len):\n","\n","  # Get the number of sequences\n","  num_sequences_train = x_train_scaled.shape[0] // seq_len\n","  num_sequences_valid = x_valid_scaled.shape[0] // seq_len\n","\n","  # Reshape x_train_scaled\n","  x_train_lstm = x_train_scaled[:num_sequences_train * seq_len, :]\n","  x_train_lstm = x_train_lstm.reshape(-1, seq_len, 3)\n","\n","  # Reshape y_train_scaled\n","  y_train_lstm = y_train_scaled[:num_sequences_train * seq_len, :]\n","  y_train_lstm = y_train_lstm.reshape(-1, seq_len, 2)\n","\n","  # Reshape x_valid_scaled\n","  x_valid_lstm = x_valid_scaled[:num_sequences_valid * seq_len, :]\n","  x_valid_lstm = x_valid_lstm.reshape(-1, seq_len, 3)\n","\n","  # Reshape x_valid_scaled\n","  y_valid_lstm = y_valid_scaled[:num_sequences_valid * seq_len, :]\n","  y_valid_lstm = y_valid_lstm.reshape(-1, seq_len, 2)\n","\n","  print(\"Shape of x_train_lstm: \", x_train_lstm.shape)\n","  print(\"Shape of y_train_lstm: \", y_train_lstm.shape)\n","  print(\"Shape of x_valid_lstm: \", x_valid_lstm.shape)\n","  print(\"Shape of y_valid_lstm: \", y_valid_lstm.shape)\n","\n","  # Define the model architecture\n","  model = tf.keras.Sequential()\n","  model.add(tf.keras.layers.LSTM(64, input_shape=(seq_len, x_train_scaled.shape[1]), return_sequences=True))\n","  model.add(tf.keras.layers.LSTM(32, return_sequences=True))\n","  model.add(tf.keras.layers.LSTM(8, return_sequences=True))\n","  model.add(tf.keras.layers.Dense(2, activation='tanh'))\n","\n","  # Define the early stopping callback\n","  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='mse', patience=10)\n","\n","  #compile model\n","  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mse'])\n","\n","  #Train the model for 100 epochs and allow early stopping\n","  history = model.fit(x_train_lstm, y_train_lstm, epochs=100, validation_data=(x_valid_lstm, y_valid_lstm), callbacks=[early_stopping], batch_size=256)\n","\t\n","  return (model, history)"],"metadata":{"id":"gfOOU7RHaO1J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#call function\n","print(\"################################## Model 5 ##################################\")\n","[model5, history5] = inverse_mapping_fcn5(10)\n","\n","# Create figure and subplots\n","fig, ax5 = plt.subplots()\n","\n","# Plot loss\n","ax5.plot(history5.history['val_loss'], label='Validation Loss')\n","ax5.set_title('Loss')\n","ax5.set_title('Loss Model 5')\n","ax5.set_xlabel('Epoch')\n","ax5.set_ylabel('Loss')\n","ax5.legend()\n","\n","# Show the plot\n","plt.show()"],"metadata":{"id":"KcsMRuOPegvm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Comparing predictions for specific example (line 42) to show how to use ANN to get Motor Activation Values\n","input = np.expand_dims(kinematics[42], axis=0)\n","expected_output = activations[42]\n","\n","#print(df.loc[13])\n","#print(\"Input: \", input)\n","#print(\"Expected: \", expected_output)\n","\n","#model0\n","#predicted_output_0 = scalerOut.inverse_transform(model0.predict(input))\n","#print(\"Prediction 0: \", predicted_output_0)\n","\n","#model1\n","#predicted_output_1 = scalerOut.inverse_transform(model1.predict(input))\n","#print(\"Prediction 1: \", predicted_output_1)\n","\n","#model2\n","#predicted_output_2 = scalerOut.inverse_transform(model2.predict(input))\n","#print(\"Prediction 2: \", predicted_output_2)\n","\n","#model3\n","#prediction3 = scalerOut.inverse_transform(model3.predict(input))\n","#print(\"Prediction 3: \", prediction3)\n","\n","#model4\n","#input_lstm = input.reshape(input.shape[0], 1, input.shape[1])\n","#prediction4 = scalerOut.inverse_transform(model4.predict(input_lstm))\n","#print(\"Prediction 4: \", prediction4)\n","\n","#model5\n","input_lstm = input.reshape(input.shape[0], 1, input.shape[1])\n","prediction5 = scalerOut.inverse_transform(model5.predict(input_lstm))\n","print(\"Prediction 5: \", prediction5)"],"metadata":{"id":"vP3QeijTcOMG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Motor Babbling**"],"metadata":{"id":"I-ffRZ0UW1eE"}},{"cell_type":"code","source":["### Motor Babbling for NTC Test Bench ###\n","\n","import sys\n","sys.path.append(\"../catkin_ws/devel/lib/python3/dist-packages\")\n","\n","import rospy\n","from bench.msg import BenchState, BenchMotorControl, BenchRecorderControl\n","import csv\n","import time\n","import random\n","import numpy as np\n","\n","def babbling_fcn(babbling_seconds=300, kinematics_activations_show=True):\n","\n","\t#local variables\n","\ttimestep=0.01\n","\trun_samples=int(np.round(babbling_seconds/timestep))\n","\tpass_chance = timestep\n","\tskip_rows = 200\n","\n","\t#TODO: Normalizing current values between 0,1. Might have to change that so that data is normalized in ANN implementation\n","\tmax_in = 1\n","\tmin_in = 0\n","\n","\t#Generating random activations in range (min_in, max_in)\n","\tmotor1_act = systemID_input_gen_fcn(babbling_seconds, pass_chance, max_in, min_in, timestep)\n","\tmotor2_act = systemID_input_gen_fcn(babbling_seconds, pass_chance, max_in, min_in, timestep)\n"," \t\n","\tbabbling_activations = np.transpose(np.concatenate([[motor1_act],[motor2_act]], axis=0))\n"," \n","\t#Save resulting kinematics data\n","\tif kinematics_activations_show:\n","\t\tkinematics_activations_show_fcn(activations=babbling_activations)\n","\t[babbling_kinematics, babbling_activations, chassis_pos] = run_activations_fcn(babbling_activations, timestep)\n"," \n","\t#return kinematics,activations map and skip skip_rows rows (setup phase)\n","\treturn babbling_kinematics[skip_rows:,:], babbling_activations[skip_rows:,:]\n","\n","def systemID_input_gen_fcn(signal_duration_in_seconds, pass_chance, max_in, min_in, timestep):\n","\n","\tnumber_of_samples = int(np.round(signal_duration_in_seconds/timestep))\n","\tsamples = np.linspace(0, signal_duration_in_seconds, number_of_samples)\n"," \n","\tgen_input = np.zeros(number_of_samples,) * min_in\n","\n","\t#generating number_of_samples random activations\n","\tfor i in range(1, number_of_samples):\n","\t\tpass_rand = np.random.uniform(0,1,1)\n","\t\n","\t\tif pass_rand < pass_chance:\n","\t\t\tgen_input[i] = ((max_in-min_in)*np.random.uniform(0,1,1)) + min_in\n","\t\telse:\n","\t\t\tgen_input[i] = gen_input[i-1]\n","\n","\treturn gen_input\n","\n","\n","def kinematics_activations_show_fcn(vs_time=False, timestep=0.01, **kwargs):\n","\n","\t#plotting the resulting kinematics or activations\n","\tsample_no_kinematics=0\n","\tsample_no_activations=0\n","\n","\t#setting up variables\n","\tif (\"kinematics\" in kwargs):\n","\t\tkinematics = kwargs[\"kinematics\"]\n","\t\tsample_no_kinematics = kinematics.shape[0]\n","\n","\tif (\"activations\" in kwargs):\n","\t\tactivations = kwargs[\"activations\"]\n","\t\tsample_no_activations = activations.shape[0]\n","\n","\tif not ((\"kinematics\" in kwargs) or (\"activations\" in kwargs)):\n","\t\traise NameError('Either kinematics or activations needs to be provided')\n","\t\n","\tif (sample_no_kinematics!=0) & (sample_no_activations!=0) & (sample_no_kinematics!=sample_no_activations):\n","\t\traise ValueError('Number of samples for both kinematics and activation matrices should be equal and not zero')\n","\t\n","\telse:\n","\t\tnumber_of_samples = np.max([sample_no_kinematics, sample_no_activations])\n","\t\tif vs_time:\n","\t\t\tx = np.linspace(0,timestep*number_of_samples,number_of_samples)\n","\t\telse:\n","\t\t\tx = range(number_of_samples)\n","\t \n","\t#plotting kinematics: angle degree, angular velocity, angular acceleration\n","\tif (\"kinematics\" in kwargs):\n","\t\tplt.figure()\n","\t\n","\t\tplt.subplot(3, 1, 1)\n","\t\tplt.plot(x, kinematics[:,0])\n","\t\tplt.ylabel('q0 (rads)')\n","\t\n","\t\tplt.subplot(3, 1, 2)\n","\t\tplt.plot(x, kinematics[:,1])\n","\t\tplt.ylabel('q0 dot (rads/s)')\n","\t\n","\t\tplt.subplot(3, 1, 3)\n","\t\tplt.plot(x, kinematics[:,2])\n","\t\tplt.ylabel('q0 double dot (rads/s^2)')\n","\t\n","\t\tplt.xlabel('motor 1 activation values')\n","\t\n","\t#plotting activation values\n","\tif (\"activations\" in kwargs):\n","\t\tplt.figure()\n","\t\n","\t\tplt.subplot(2, 1, 1)\n","\t\tplt.plot(x, activations[:,0])\n","\t\tplt.ylabel('motor 1 activation values')\n","\t\n","\t\tplt.subplot(2, 1, 2)\n","\t\tplt.plot(x, activations[:,1])\n","\t\tplt.ylabel('motor 2 activation values')\n","\n","\tplt.show(block=True)\n"," \n","def run_activations_fcn(activations, timestep):\n","#todo"],"metadata":{"id":"rZ-rdW-cW7Dc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Reinforcement Learning to refine Inverse Kineatics**"],"metadata":{"id":"RKMt1nBByjv7"}},{"cell_type":"code","source":["#Reinforement Learning for particular Learning to refine inverse mapping\n","#model: ANN trained during Motor Babbling\n","#cum_kinematics: kinematics as part of the cummulative training_set collected during Motor Babbling and RL -> Refine ANN\n","#cum_activations: activations as part of the cummulative training_set collected during Motor Babbling and RL -> Refine ANN\n","#penalty_thresh: predefined penalty_threshold to decide which Policy should be choosen\n","#energy_cost_weight: predefined weight for calculating activation values during execution in experiment\n","#refinement: True when ANN should be refined\n","\n","\n"," def learn_to_move_2_fcn(model, cum_kinematics, cum_activations, penalty_thresh=42, energy_cost_weight=0, refinement = False): #need to set default for penalty_thresh\n","\t\n","\t#initializing local variables\n","\texploration_limit = 100\n","\texploitation_limit = 15\n","\tprev_penalty = np.array([0])\n","\tlowest_penalty_so_far = np.array([0])\n","\tbest_model= model\n","\tall_penaltys = []\n","\texploration_run_no = 0\n","\texploitation_run_no = 0\n","\tnew_features = gen_features_fcn(penalty_thresh=penalty_thresh, lowest_penalty_so_far=lowest_penalty_so_far, feat_vec_length=10) #might have to change feat_vec_length\n","\tbest_features_so_far = new_features\n","\texploration_limit_reached = False\n","\n","\t#Check necessaty condition for both exploration phase and exploitation pahse\n","\twhile exploitation_run_no <= exploitation_limit and not exploration_limit_reached:\n","\n","\t\t#count iterations for both exploration and exploitation phase\n","\t\tif lowest_penalty_so_far < penalty_thresh:\n","\t\t\texploration_run_no += 1\n","\t\telse:\n","\t\t\texploitation_run_no += 1\n","\n","\t\t#generate new feature vector F_k. Depending on lowest_penalty_so_far the function gen_features_fcn will choose the correct Policy\n","\t\tnew_features = gen_features_fcn(penalty_thresh=penalty_thresh, lowest_penalty_so_far=lowest_penalty_so_far, prev_penalty=prev_penalty, best_features_so_far=best_features_so_far)\n","\n","\t\t#Execute generated kinematics to interact with environment and receive estimations and real data as well as the penalty\n","\t\t[prev_penalty, est_attempt_kinematics, est_attempt_activations, real_attempt_kinematics, real_attempt_activations] = feat_to_run_attempt_fcn(features=new_features, model=model, energy_cost_weight=energy_cost_weight, feat_show=False)\n","\t\t\n","\t\t#concatinate data to train model and refine\n","\t\t[cum_kinematics, cum_activations] = concatinate_data_fcn(cum_kinematics, cum_activations, real_attempt_kinematics, real_attempt_activations, throw_percentage = 0.20)\n","\t\n","\t\t#Append new penalty\n","\t\tall_penaltys = np.append(all_penaltys, prev_penalty)\n","\n","\t\tif prev_penalty > lowest_penalty_so_far:\n","\t\t\tlowest_penalty_so_far = prev_penalty\n","\t\t\tbest_features_so_far = new_features\n","\t\t\tbest_model = copy_model_fcn(model)\n","\n","\t\tif refinement:\n","\t\t\tmodel = inverse_mapping_fcn1(cum_kinematics, cum_activations, prior_model=model)\n","\n","\t\tprint(\"best penalty so far: \", lowest_penalty_so_far)\n","\t\tif exploration_run_no == exploration_limit and lowest_penalty_so_far < penalty_thresh:\n","\t\t\texploration_limit_reached = True\n","\n","\t#update after run\n","\t[prev_penalty_best, attempt_kinematics_best, est_attempt_activations_best, real_attempt_kinematics_best, real_attempt_activations_best]= \\\n","\tfeat_to_run_attempt_fcn(features = best_features_so_far, model=best_model, energy_cost_weight=energy_cost_weight, feat_show=False)\n","\n","\tprint(\"all_penalty: \", all_penaltys)\n","\tprint(\"prev_penalty_best: \", prev_penalty_best)\n","\n","\treturn lowest_penalty_so_far, all_penaltys, best_features_so_far, real_attempt_activations, exploration_run_no"],"metadata":{"id":"geIVrnnH84ZE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Policy1 + Policy2\n","def gen_features_fcn(penalty_thresh, lowest_penalty_so_far, **kwargs):\n","\n","\t#local variables to generate new vectors\n","\tfeat_min = 0.4\n","\tfeat_max = 0.9\n","\n","\tif (\"best_features_so_far\" in kwargs):\n","\t\tbest_features_so_far = kwargs[\"best_features_so_far\"]\n","\telif (\"feat_vec_length\" in kwargs):\n","\t\tbest_features_so_far = np.random.uniform(feat_min,feat_max,kwargs[\"feat_vec_length\"])\n","\telse:\n","\t\traise NameError('Either best_features_so_far or feat_vec_length needs to be provided')\n","\t\n","\tif lowest_penalty_so_far < penalty_thresh:\n","\t\t#Policy 1: Generate random kinematics data\n","\t\tnew_features = np.random.uniform(feat_min, feat_max, best_features_so_far.shape[0])\n","\telse:\n","\t\t#Policy 2: Use Multivariate Gaussian Distribution Based Stochastic Search\n","\t\tsigma= np.max([(2*penalty_thresh - lowest_penalty_so_far)/100, 0.01])# should be inversly proportional to penalty\n","\t\tnew_features = np.zeros(best_features_so_far.shape[0],)\n","\t\n","\t\tfor i in range(0,len(new_features)):\n","\t\t\tnew_features[i] = np.random.normal(best_features_so_far[i], sigma)\n","\t \n","\t \t#Building new F_k using the new_features from above\n","\t\tnew_features = np.maximum(new_features, feat_min * np.ones(best_features_so_far.shape[0],))\n","\t\tnew_features = np.minimum(new_features, feat_max * np.ones(best_features_so_far.shape[0],))\n","\t\n","\treturn new_features"],"metadata":{"id":"kAePMSsDy1vw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Execute kinematics to interact with environment\n","def feat_to_run_attempt_fcn(features, model,energy_cost_weight=0, feat_show=False):\n","\t[q0_filtered, q1_filtered] = feat_to_positions_fcn(features, show=feat_show)\n"," \n","\tstep_kinematics = positions_to_kinematics_fcn(q0_filtered, q1_filtered, timestep = 0.01)\n"," \n","\tattempt_kinematics = step_to_attempt_kinematics_fcn(step_kinematics=step_kinematics)\n"," \n","\test_attempt_activations = estimate_activations_fcn(model=model, desired_kinematics=attempt_kinematics)\n"," \n"," \t#not implemented yet. Returns Hardcoded values\n","\t[real_attempt_kinematics, real_attempt_activations, chassis_pos]=run_activations_fcn(MuJoCo_model_name=MuJoCo_model_name, est_activations=est_attempt_activations, Mj_render=Mj_render)\n","\n","\treal_attempt_energy = np.square(real_attempt_activations).sum(0).sum(0)\n"," \n","\tprev_penalty = chassis_pos[-1] - energy_cost_weight*real_attempt_energy\n","\n","\treturn prev_penalty, attempt_kinematics, est_attempt_activations, real_attempt_kinematics, real_attempt_activations"],"metadata":{"id":"LVqXNC-KzAGy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def step_to_attempt_kinematics_fcn(step_kinematics, number_of_steps_in_an_attempt = 10):\n","\tattempt_kinematics=np.matlib.repmat(step_kinematics,number_of_steps_in_an_attempt,1)\n","\treturn(attempt_kinematics)"],"metadata":{"id":"Uh_MpRE5zKkk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Merges new data to the current dataset after throwing out the first few samples (defined by throw_percentage)\n","def concatinate_data_fcn( cum_kinematics, cum_activations, kinematics, activations, throw_percentage = 0.20):\n","\tsize_of_incoming_data = kinematics.shape[0]\n","\tsamples_to_throw = int(np.round(throw_percentage * size_of_incoming_data))\n"," \n","\t#concatenate after skipping the firs #samples_to_throw rows\n","\tcum_kinematics = np.concatenate([cum_kinematics, kinematics[samples_to_throw:,:]])\n","\tcum_activations = np.concatenate([cum_activations, activations[samples_to_throw:,:]])\n"," \n","\treturn cum_kinematics, cum_activations"],"metadata":{"id":"hvfvInazzYNO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def copy_model_fcn(original_model):\n","\tconfig=original_model.get_config()\n","\tnew_model=tf.keras.Sequential.from_config(config)\n","\tnew_model.set_weights(original_model.get_weights())\n","\tnew_model.compile(optimizer=tf.train.AdamOptimizer(0.01),loss='mse',metrics=['mse'])  # mean squared error\n","\treturn new_model"],"metadata":{"id":"_CyVqsqNziu4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#calculate \n","def feat_to_positions_fcn(features, timestep=0.01, cycle_duration_in_seconds = 1.3, show=False):\n","\tnumber_of_features = features.shape[0]\n","\teach_feature_length =  int(np.round((cycle_duration_in_seconds/number_of_features)/timestep))\n","\tfeat_angles = np.linspace(0, 2*np.pi*(number_of_features/(number_of_features+1)), number_of_features)\n","\tq0_raw = features*np.sin(feat_angles)\n","\tq1_raw = features*np.cos(feat_angles)\n","\tq0_scaled = (q0_raw*np.pi/3)\n","\tq1_scaled = -1*((-1*q1_raw+1)/2)*(np.pi/2) # since the mujoco model goes from 0 to -pi/2\n","\tq0_scaled_extended = np.append(q0_scaled, q0_scaled[0])\n","\tq1_scaled_extended = np.append(q1_scaled, q1_scaled[0])\n","\n","\tq0_scaled_extended_long = np.array([])\n","\tq1_scaled_extended_long = np.array([])\n","\tfor ii in range(features.shape[0]):\n","\t\tq0_scaled_extended_long = np.append(\n","\t\t\tq0_scaled_extended_long, np.linspace(\n","\t\t\t\tq0_scaled_extended[ii], q0_scaled_extended[ii+1], each_feature_length))\n","\t\tq1_scaled_extended_long = np.append(\n","\t\t\tq1_scaled_extended_long, np.linspace(\n","\t\t\t\tq1_scaled_extended[ii], q1_scaled_extended[ii+1], each_feature_length))\n","\tq0_scaled_extended_long_3 = np.concatenate(\n","\t\t[q0_scaled_extended_long[:-1], q0_scaled_extended_long[:-1], q0_scaled_extended_long])\n","\tq1_scaled_extended_long_3 = np.concatenate(\n","\t\t[q1_scaled_extended_long[:-1], q1_scaled_extended_long[:-1], q1_scaled_extended_long])\n","\n","\tfir_filter_length = int(np.round(each_feature_length/(1)))\n","\tb=np.ones(fir_filter_length,)/fir_filter_length # a simple moving average filter > users can \n","\t#change these if they need smoother pattern\n","\ta=1\n","\tq0_filtered_3 = signal.filtfilt(b, a, q0_scaled_extended_long_3)\n","\tq1_filtered_3 = signal.filtfilt(b, a, q1_scaled_extended_long_3)\n","\n","\tq0_filtered = q0_filtered_3[q0_scaled_extended_long.shape[0]:2*q0_scaled_extended_long.shape[0]-1] # length = 1999 (the \n","\t#very last was ommited since it is going to be the first one on the next cycle)\n","\tq1_filtered = q1_filtered_3[q1_scaled_extended_long.shape[0]:2*q1_scaled_extended_long.shape[0]-1]\n","\tif show:\n","\t\tplt.figure()\n","\t\tplt.scatter(q0_scaled, q1_scaled)\n","\t\tplt.plot(q0_filtered, q1_filtered)\n","\t\tplt.xlabel(\"q0\")\n","\t\tplt.ylabel(\"q1\")\n","\t\tplt.show(block=True)\n","\treturn q0_filtered, q1_filtered"],"metadata":{"id":"qwQdyVihzr05"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def positions_to_kinematics_fcn(q0, q1, timestep = 0.01):\n","\tkinematics=np.transpose(\n","\tnp.concatenate(\n","\t\t(\n","\t\t\t[[q0],\n","\t\t\t[np.gradient(q0)/timestep],\n","\t\t\t[np.gradient(np.gradient(q0)/timestep)/timestep],\n","\t\t\t[q1],\n","\t\t\t[np.gradient(q1)/timestep],\n","\t\t\t[np.gradient(np.gradient(q1)/timestep)/timestep]]),\n","\t\taxis=0\n","\t\t)\n","\t)\n","\treturn kinematics"],"metadata":{"id":"NFuzekSjzyV1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def estimate_activations_fcn(model, desired_kinematics):\n","\n","\tprint(\"running the model\")\n"," \n","\test_activations = model.predict(desired_kinematics)\n","\n","\treturn est_activations"],"metadata":{"id":"7JCUcceaz442"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# results from Hardware/Simulation. Returns hardcoded values at the moment\n","def run_activations_fcn(est_activations, timestep=0.01):\n","\treal_attempt_kinematics = [1543, 119.78934140629462, 597.8981090205831]\n","\treal_attempt_activations = [2.7492387, 0.87028396]\n","\tchassis_pos = [0,0]\n","\treturn real_attempt_kinematics, real_attempt_activations, chassis_pos"],"metadata":{"id":"3popyNKL0AYA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Main**"],"metadata":{"id":"z3CY20seFUFT"}},{"cell_type":"code","source":["# next is to add accel and see the difference\n","# add stiffness too\n","import tensorflow as tf\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import pickle\n","from warnings import simplefilter\n","\n","simplefilter(action='ignore', category=FutureWarning)\n","\n","experiment_ID = \"rl_transfer_learning_1\"\n","\n","mc_run_number = 1\n","babbling_time = 3\n","number_of_refinements = 0\n","errors_all_A_A = np.zeros([2, number_of_refinements+1, mc_run_number])\n","errors_all_A_B = np.zeros([2, number_of_refinements+1, mc_run_number])\n","errors_all_B_B = np.zeros([2, number_of_refinements+1, mc_run_number])\n","\n","stiffness_version_A = 8\n","MuJoCo_model_name_A=\"nmi_leg_w_chassis_air_v{}.xml\".format(stiffness_version_A)\n","MuJoCo_model_name_A_walk=\"nmi_leg_w_chassis_air_v{}_walk.xml\".format(stiffness_version_A)\n","stiffness_version_B = 3\n","MuJoCo_model_name_B=\"nmi_leg_w_chassis_air_v{}.xml\".format(stiffness_version_B)\n","MuJoCo_model_name_B_walk=\"nmi_leg_w_chassis_air_v{}_walk.xml\".format(stiffness_version_B)\n","\n","random_seed = -1\n","\n","for mc_counter in range(mc_run_number):\n","\trandom_seed+=1\n","\t# train model_A\n","\tnp.random.seed(random_seed) # change the seed for different initial conditions\n","\ttf.random.set_random_seed(random_seed)\n","\t[babbling_kinematics, babbling_activations] =\\\n","\t\tbabbling_fcn(\n","\t\t\tMuJoCo_model_name=MuJoCo_model_name_A,\n","\t\t\tsimulation_minutes=babbling_time,\n","\t\t\tkinematics_activations_show=False)\n","\tmodel_A_babble = inverse_mapping_fcn2(\n","\t\tkinematics=babbling_kinematics,\n","\t\tactivations=babbling_activations,\n","\t\tlog_address=\"./logs/{}/scalars/babble_A_mc_run{}/\".format(experiment_ID, mc_counter),\n","\t\tearly_stopping=False)\n","\tcum_kinematics_A_babble = babbling_kinematics\n","\tcum_activations_A_babble = babbling_activations\n","\t#A_A test\n","\tnp.random.seed(random_seed) # change the seed for different initial conditions\n","\ttf.random.set_random_seed(random_seed)\n","\tmodel_A_refined_A=tf.keras.models.clone_model(model_A_babble)\n","\tmodel_A_refined_A.compile(optimizer=tf.train.AdamOptimizer(0.01),\n","          loss='mse',       # mean squared error\n","          metrics=['mse'])  # mean squared error\n","\t[model_A_refined_A, errors, cum_kinematics_A_refined, cum_activations_A_refined] =\\\n","\t\tin_air_adaptation_fcn(\n","\t\t\tMuJoCo_model_name=MuJoCo_model_name_A,\n","\t\t\tmodel=model_A_refined_A,\n","\t\t\tbabbling_kinematics=cum_kinematics_A_babble,\n","\t\t\tbabbling_activations=cum_activations_A_babble,\n","\t\t\tnumber_of_refinements=number_of_refinements,\n","\t\t\tlog_address=\"./logs/{}/scalars/refine_A_A_mc_run{}/\".format(experiment_ID, mc_counter),\n","\t\t\terror_plots_show=False,\n","\t\t\tMj_render=False)\n","\t#import pdb; pdb.set_trace()\n","\terrors_all_A_A[:,:, mc_counter] = [errors[0],errors[1]]\n","\t#A_B test\n","\tnp.random.seed(random_seed) # change the seed for different initial conditions\n","\ttf.random.set_random_seed(random_seed)\n","\tmodel_A_refined_B=tf.keras.models.clone_model(model_A_babble)\n","\tmodel_A_refined_B.compile(optimizer=tf.train.AdamOptimizer(0.01),\n","      loss='mse',       # mean squared error\n","      metrics=['mse'])  # mean squared error\n","\t[model_A_refined_B, errors, cum_kinematics_B_refined, cum_activations_B_refined] =\\\n","\t\tin_air_adaptation_fcn(\n","\t\t\tMuJoCo_model_name=MuJoCo_model_name_B,\n","\t\t\tmodel=model_A_refined_B,\n","\t\t\tbabbling_kinematics=cum_kinematics_A_babble,\n","\t\t\tbabbling_activations=cum_activations_A_babble,\n","\t\t\tnumber_of_refinements=number_of_refinements,\n","\t\t\tlog_address=\"./logs/{}/scalars/refine_A_B_mc_run{}/\".format(experiment_ID, mc_counter),\n","\t\t\terror_plots_show=False,\n","\t\t\tMj_render=False)\n","\terrors_all_A_B[:,:, mc_counter] = [errors[0],errors[1]]\n","## saving the results\n","np.save(\"./results/{}/errors_all_A_A\".format(experiment_ID),errors_all_A_A)\n","np.save(\"./results/{}/errors_all_A_B\".format(experiment_ID),errors_all_A_B)\n","np.save(\"./results/{}/errors_all_B_B\".format(experiment_ID),errors_all_B_B)\n","\n","np.random.seed(random_seed+2) # change the seed for different initial conditions\n","tf.random.set_random_seed(random_seed+2)\n","## Higher level learning (RL)\n","[ lowest_penalty_so_far, all_penaltys, best_features_so_far, real_attempt_activations ]=\\\n"," learn_to_move_fcn(\n"," \tMuJoCo_model_name=MuJoCo_model_name_A_walk,\n"," \tmodel=model_A_refined_A,\n"," \tcum_kinematics=cum_kinematics_A_babble,\n"," \tcum_activations=cum_activations_A_babble,\n"," \tpenalty_thresh=6,\n"," \trefinement=False,\n"," \tMj_render=False)\n","#import pdb; pdb.set_trace()\n","[penaltyA_A, _, _, _, _]=\\\n","feat_to_run_attempt_fcn(MuJoCo_model_name=MuJoCo_model_name_A_walk, features=best_features_so_far, model=model_A_refined_A, feat_show=True, Mj_render=True)\n","[penaltyA_B, _, _, _, _]=\\\n","feat_to_run_attempt_fcn(MuJoCo_model_name=MuJoCo_model_name_B_walk, features=best_features_so_far, model=model_A_refined_A, feat_show=True, Mj_render=False)\n","[penaltyAB_B, _, _, _, _]=\\\n","feat_to_run_attempt_fcn(MuJoCo_model_name=MuJoCo_model_name_B_walk, features=best_features_so_far, model=model_A_refined_B, feat_show=True, Mj_render=False)\n","print(\"penaltyA_A: \", penaltyA_A)\n","print(\"penaltyA_B: \", penaltyA_B)\n","print(\"penaltyAB_B: \", penaltyAB_B)\n","\n","\n","## printing the results\n","# print(\"errors_mean: \",errors_all_A_A.mean(1))\n","# print(\"errors_std: \",errors_all_A_A.std(1))\n","# print(\"errors_mean: \",errors_all_A_B.mean(1))\n","# print(\"errors_std: \",errors_all_A_B.std(1))\n","#import pdb; pdb.set_trace()"],"metadata":{"id":"GiCJl0VAFZxj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6gcNT1-mWsGu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"nxFRfgz3Z-hf"}}]}